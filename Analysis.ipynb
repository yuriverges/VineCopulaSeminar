{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import arch\n",
    "import pyvinecopulib as pv\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from SourceCodes.invariance_analysis import quick_invariance_analysis\n",
    "from SourceCodes.garch_aux_methods import zero_mean_garch_1_1_scenario\n",
    "\n",
    "\n",
    "columns_mappings = {'ES1 Index': 'SP500',\n",
    "                    'NQ1 Index': 'Nasdaq100',\n",
    "                    'VG1 Index': 'Euro Stox50',\n",
    "                    'BZ1 Index': 'Ibovespa',\n",
    "                    'TY1 Comdty':'10-Year Treasury',\n",
    "                    'RX1 Comdty': 'Euro Bund',\n",
    "                    'EC1 Curncy': 'EUR/USD',\n",
    "                    'BP1 Curncy': 'GBP/USD',\n",
    "                    'UC1 Curncy': 'USD/BRL',\n",
    "                    'CL1 Comdty': 'WTI',\n",
    "                    'CO1 Comdty': 'Brent'}\n",
    "\n",
    "selected_securities = ['SP500', 'Nasdaq100', 'Ibovespa', '10-Year Treasury','USD/BRL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"Data/data.csv\", index_col=\"Dates\", date_parser = pd.to_datetime).rename(columns=columns_mappings)[selected_securities]\n",
    "df.sort_index(inplace=True)\n",
    "returns_scale_factor = 100\n",
    "df_log_ret = np.log(df).diff() * returns_scale_factor\n",
    "n = df.shape[0]\n",
    "n_os = 252\n",
    "n_scenarios = 1000\n",
    "seeds = [int(x) for x in np.ones(len(selected_securities)).tolist()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Quick Invariance Analysis\n",
    "for item in df_log_ret.columns:\n",
    "    fig, axs = quick_invariance_analysis(df_log_ret[item].iloc[:-n_os], n_chunks=3, nbins=30)\n",
    "    fig.set_size_inches(20, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fitting a GARCH(1,1) Model and\n",
    "model_list = []\n",
    "\n",
    "for k, item in enumerate(df_log_ret):\n",
    "    mdl = list()\n",
    "    mdl.append(arch.arch_model(df_log_ret.iloc[1:-n_os, k] , mean=\"Zero\", vol=\"GARCH\", p=1, q=1, dist=\"normal\"))\n",
    "    mdl[0].constraints()\n",
    "    mdl.append(mdl[0].fit())\n",
    "    model_list.append(mdl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example - Univariate Fitting\n",
    "fig = model_list[0][1].plot(scale=252)\n",
    "fig.set_size_inches(10, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating the matrix of residuals and scatter plotting\n",
    "for k, item in enumerate(model_list):\n",
    "    if k == 0:\n",
    "        df_log_resid = pd.DataFrame(item[1].std_resid)\n",
    "        df_log_resid.rename(columns={df_log_resid.columns[-1]:item[0].y.name}, inplace=True)\n",
    "    else:\n",
    "        df_log_resid = pd.concat([df_log_resid, pd.DataFrame(item[1].std_resid)], axis=1)\n",
    "        df_log_resid.rename(columns={df_log_resid.columns[-1]:item[0].y.name}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Quick Invariance Analysis - Of residuals\n",
    "for item in df_log_resid.columns:\n",
    "    fig, axs = quick_invariance_analysis(df_log_resid[item], n_chunks=3, nbins=30)\n",
    "    fig.set_size_inches(20, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating the pseudo-observations - Estimated Probability Integral Transform\n",
    "for k, item in enumerate(model_list):\n",
    "    if k == 0:\n",
    "        df_log_resid_pseudo_observations = pd.DataFrame(sci.stats.norm.cdf(df_log_resid.iloc[:, k]))\n",
    "    else:\n",
    "        df_log_resid_pseudo_observations = pd.concat([df_log_resid_pseudo_observations, pd.Series(sci.stats.norm.cdf(df_log_resid.iloc[:, k]))], axis=1, ignore_index=True)\n",
    "\n",
    "df_log_resid_pseudo_observations.columns = df_log_resid.columns\n",
    "df_log_resid_pseudo_observations.columns = df_log_resid.columns\n",
    "df_log_resid_pseudo_observations.index=df_log_resid.index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Empirical Copula Plotting\n",
    "fig1 =  px.scatter_matrix(data_frame=df_log_resid_pseudo_observations,\n",
    "                          dimensions=df_log_resid_pseudo_observations.columns,\n",
    "                          height=2000, width=2000)\n",
    "fig1.update_traces(marker=dict(size=4, line=dict(width=1)), opacity=0.6, showlegend=False)\n",
    "#fig1.update_traces(diagonal_visible=False)\n",
    "fig1.update_layout(plot_bgcolor = \"#ffebe3\", colorway = [\"#ff774a\"], title = \"Empirical Copula\")\n",
    "fig1.update_layout({\"yaxis\"+str(i+1): dict(range = [0, 1]) for i in range(1, len(df.columns))})\n",
    "fig1.update_layout({\"xaxis\"+str(i+1): dict(range = [0, 1]) for i in range(1, len(df.columns))})\n",
    "fig1.update_xaxes(visible=True, showgrid=True)\n",
    "fig1.update_yaxes(visible=True, showgrid=True)\n",
    "fig1.write_html(\"HTML/file.html\")\n",
    "#fig1.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Meta Distribution - Distribution which is constructed by an arbitrary copula and arbitrary marginal distributions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating Vine - Structure\n",
    "copVine = pv.Vinecop(d = df_log_resid_pseudo_observations.columns.shape[0])\n",
    "\n",
    "# Selecting Most Appropriate Model Given pseudo-observations\n",
    "copVine.select(data=df_log_resid_pseudo_observations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Simulating U - Given Vine - Empirical X Simulated Copulas\n",
    "n_sim = 10000\n",
    "u_sim = pd.DataFrame(copVine.simulate(n_sim, seeds=seeds), columns=df_log_resid_pseudo_observations.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting simulation results given Vine\n",
    "fig2 =  px.scatter_matrix(data_frame=u_sim,\n",
    "                          dimensions=u_sim.columns,\n",
    "                          height=2000, width=2000)\n",
    "fig2.update_traces(marker=dict(size=4, line=dict(width=1)), opacity=0.6, showlegend=False)\n",
    "#fig1.update_traces(diagonal_visible=False)\n",
    "fig2.update_layout(plot_bgcolor = \"#ffebe3\", colorway = [\"#ff774a\"], title = \"Simulated Data - Given Vine Structure\")\n",
    "fig2.update_layout({\"yaxis\"+str(i+1): dict(range = [0, 1]) for i in range(1, len(df.columns))})\n",
    "fig2.update_layout({\"xaxis\"+str(i+1): dict(range = [0, 1]) for i in range(1, len(df.columns))})\n",
    "fig2.update_xaxes(visible=True, showgrid=True)\n",
    "fig2.update_yaxes(visible=True, showgrid=True)\n",
    "fig2.write_html(\"HTML/simulated.html\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scenario Simulation - Vine Copula\n",
    "scenarios_copula = list()\n",
    "\n",
    "for k in range(n_scenarios):\n",
    "    scenario_copula = dict()\n",
    "    scenario_copula['u_sim'] = pd.DataFrame(copVine.simulate(n_os), columns=df_log_resid_pseudo_observations.columns)\n",
    "\n",
    "    sim_given_models_copula = []\n",
    "    for d, model in enumerate(model_list):\n",
    "        # Filterting data - Given Models + Simulated Residuals\n",
    "        sim_given_models_copula.append(zero_mean_garch_1_1_scenario(sci.stats.norm.ppf(scenario_copula['u_sim'].iloc[:, d]), model[1].conditional_volatility,\n",
    "                                                             model[1].resid, w=model[1].params.omega, alpha=model[1].params['alpha[1]'],\n",
    "                                                             beta=model[1].params['beta[1]']))\n",
    "        # Return projection for the proposed horizon\n",
    "        if d == 0:\n",
    "            projected_returns_simulation_copula = pd.DataFrame(pd.Series(np.exp(np.cumsum(sim_given_models_copula[d][0] / returns_scale_factor)) - 1))\n",
    "        else:\n",
    "            projected_returns_simulation_copula = pd.concat([projected_returns_simulation_copula, pd.Series(np.exp(np.cumsum(sim_given_models_copula[d][0] / returns_scale_factor)) - 1)], axis=1, ignore_index=True)\n",
    "\n",
    "    projected_returns_simulation_copula.index = df_log_ret.index[-n_os:]\n",
    "    projected_returns_simulation_copula.columns = selected_securities\n",
    "\n",
    "    scenario_copula[\"sim_given_models\"] = sim_given_models_copula\n",
    "    scenario_copula[\"projections\"] = projected_returns_simulation_copula\n",
    "\n",
    "    scenarios_copula.append(scenario_copula)\n",
    "\n",
    "# Scenarios Projections\n",
    "scenario_projections_copula = np.zeros((n_scenarios, len(selected_securities)))\n",
    "\n",
    "for k, scenario in enumerate(scenarios_copula):\n",
    "    scenario_projections_copula[k, :] = scenario[\"projections\"].iloc[-1, :].to_numpy()\n",
    "\n",
    "scenario_projections_copula = pd.DataFrame(scenario_projections_copula, columns = selected_securities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ledoit and Wolf - Shrinked Normal Covariance Estimate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.covariance import LedoitWolf, OAS\n",
    "from sklearn.covariance import ShrunkCovariance, empirical_covariance, log_likelihood\n",
    "from scipy import linalg\n",
    "\n",
    "n_split = np.floor(df_log_resid.shape[0] / 2).astype(int)\n",
    "X_train = df_log_resid.iloc[0:n_split, :]\n",
    "X_test = df_log_resid.iloc[n_split:, :]\n",
    "\n",
    "shrinkages = np.logspace(-2, 0, 30)\n",
    "\n",
    "# GridSearch for an optimal shrinkage coefficient\n",
    "tuned_parameters = [{\"shrinkage\": shrinkages}]\n",
    "cv = GridSearchCV(ShrunkCovariance(), tuned_parameters)\n",
    "cv.fit(X_train)\n",
    "\n",
    "# Ledoit-Wolf optimal shrinkage coefficient estimate\n",
    "lw = LedoitWolf()\n",
    "lw_fit = lw.fit(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scenario Simulation - Ledoit and Wolf\n",
    "scenarios_ld = list()\n",
    "\n",
    "for k in range(n_scenarios):\n",
    "    scenario_ld = dict()\n",
    "    scenario_ld['std_resid_sim'] = pd.DataFrame(np.random.multivariate_normal(mean=np.zeros(shape=(len(selected_securities))), cov=lw_fit.covariance_, size=n_os), columns=selected_securities)\n",
    "\n",
    "    sim_given_models_ld = []\n",
    "    for d, model in enumerate(model_list):\n",
    "        # Filterting data - Given Models + Simulated Residuals\n",
    "        sim_given_models_ld.append(zero_mean_garch_1_1_scenario(scenario_ld['std_resid_sim'].iloc[:, d], model[1].conditional_volatility,\n",
    "                                                             model[1].resid, w=model[1].params.omega, alpha=model[1].params['alpha[1]'],\n",
    "                                                             beta=model[1].params['beta[1]']))\n",
    "        # Return projection for the proposed horizon\n",
    "        if d == 0:\n",
    "            projected_returns_simulation_ld = pd.DataFrame(pd.Series(np.exp(np.cumsum(sim_given_models_ld[d][0] / returns_scale_factor)) - 1))\n",
    "        else:\n",
    "            projected_returns_simulation_ld = pd.concat([projected_returns_simulation_ld, pd.Series(np.exp(np.cumsum(sim_given_models_ld[d][0] / returns_scale_factor)) - 1)], axis=1, ignore_index=True)\n",
    "\n",
    "    projected_returns_simulation_ld.index = df_log_ret.index[-n_os:]\n",
    "    projected_returns_simulation_ld.columns = selected_securities\n",
    "\n",
    "    scenario_ld[\"sim_given_models\"] = sim_given_models_ld\n",
    "    scenario_ld[\"projections\"] = projected_returns_simulation_ld\n",
    "\n",
    "    scenarios_ld.append(scenario_ld)\n",
    "\n",
    "# Scenarios Projections\n",
    "scenario_projections_ld = np.zeros((n_scenarios, len(selected_securities)))\n",
    "\n",
    "for k, scenario in enumerate(scenarios_ld):\n",
    "    scenario_projections_ld[k, :] = scenario[\"projections\"].iloc[-1, :].to_numpy()\n",
    "\n",
    "scenario_projections_ld = pd.DataFrame(scenario_projections_ld, columns = selected_securities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Volatilities - Vine Copula\n",
    "print(scenario_projections_copula.std())\n",
    "\n",
    "# Correlation - Vine Copula\n",
    "print(scenario_projections_copula.corr())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Volatilities - Ledoit and Wolf\n",
    "print(scenario_projections_ld.std())\n",
    "\n",
    "# Correlation Ledoit and Wolf\n",
    "print(scenario_projections_ld.corr())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot( sci.stats.t.ppf(scenario['u_sim'].iloc[:, 0], df=model.params.nu, loc=0, scale=1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://www.oreilly.com/library/view/bayesian-statistics-an/9781118359778/OEBPS/c1-sec1-0007.htm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Invariance Analysis\n",
    "fig1 =  px.scatter_matrix(data_frame=df_log_ret.iloc[1:, :],\n",
    "                          dimensions=df_log_ret.columns[1:],\n",
    "                          height=4000, width=4000,\n",
    "                          symbol=\"sample\", color=\"sample\")\n",
    "fig1.update_traces(marker=dict(size=4, line=dict(width=1)), opacity=0.6, showlegend=False)\n",
    "#fig1.update_traces(diagonal_visible=False)\n",
    "fig1.update_layout(plot_bgcolor = \"#ffebe3\", colorway = [\"#ff774a\"], title = \"Scatter plots\")\n",
    "fig1.update_layout({\"yaxis\"+str(i+1): dict(range = [-0.15, 0.15]) for i in range(1, len(df.columns))})\n",
    "fig1.update_layout({\"xaxis\"+str(i+1): dict(range = [-0.15, 0.15]) for i in range(1, len(df.columns))})\n",
    "fig1.update_xaxes(visible=True, showgrid=True)\n",
    "fig1.update_yaxes(visible=True, showgrid=True)\n",
    "fig1.write_html(\"HTML/file.html\")\n",
    "\n",
    "fig1.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
